{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6. Pré-processamento completo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EpvUWlrvq335",
        "tHzQ5aR3uNmB",
        "ZLuW2Uo92_c4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpvUWlrvq335"
      },
      "source": [
        "# 1. Limpeza de texto e tokenização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kumHxwAoMcYP"
      },
      "source": [
        "# Importando biblioteca de regex\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39zWEICmsIbD"
      },
      "source": [
        "# Definição de função para limpar um texto\n",
        "def limpar_tokenizar_texto(sentenca):\n",
        "  return re.sub(r'([^\\s\\w]|_)+', ' ', sentenca).split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Jk_uTost_S"
      },
      "source": [
        "# Sentença que usaremos para testar nossa função\n",
        "sentenca = \"\"\"São Paulo is the most successful team from Brazil, with 12 international titles. \n",
        "It is also one of the most successful South American clubs with 21 state titles, 6 Brasileirão titles, \n",
        "3 Copa Libertadores titles, 1 Copa Sudamericana, 1 Supercopa Libertadores, 1 Copa CONMEBOL, \n",
        "1 Copa Masters CONMEBOL, 2 Recopa Sudamericanas, 2 Intercontinental Cup and 1 FIFA Club World Cup.\"\"\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9OWcDCctyfm",
        "outputId": "f4168b5f-2c70-40e3-d4c6-e319666d5786"
      },
      "source": [
        "# Limpeza e tokenização do texto\n",
        "tokens = limpar_tokenizar_texto(sentenca)\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['São',\n",
              " 'Paulo',\n",
              " 'is',\n",
              " 'the',\n",
              " 'most',\n",
              " 'successful',\n",
              " 'team',\n",
              " 'from',\n",
              " 'Brazil',\n",
              " 'with',\n",
              " '12',\n",
              " 'international',\n",
              " 'titles',\n",
              " 'It',\n",
              " 'is',\n",
              " 'also',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'successful',\n",
              " 'South',\n",
              " 'American',\n",
              " 'clubs',\n",
              " 'with',\n",
              " '21',\n",
              " 'state',\n",
              " 'titles',\n",
              " '6',\n",
              " 'Brasileirão',\n",
              " 'titles',\n",
              " '3',\n",
              " 'Copa',\n",
              " 'Libertadores',\n",
              " 'titles',\n",
              " '1',\n",
              " 'Copa',\n",
              " 'Sudamericana',\n",
              " '1',\n",
              " 'Supercopa',\n",
              " 'Libertadores',\n",
              " '1',\n",
              " 'Copa',\n",
              " 'CONMEBOL',\n",
              " '1',\n",
              " 'Copa',\n",
              " 'Masters',\n",
              " 'CONMEBOL',\n",
              " '2',\n",
              " 'Recopa',\n",
              " 'Sudamericanas',\n",
              " '2',\n",
              " 'Intercontinental',\n",
              " 'Cup',\n",
              " 'and',\n",
              " '1',\n",
              " 'FIFA',\n",
              " 'Club',\n",
              " 'World',\n",
              " 'Cup']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHzQ5aR3uNmB"
      },
      "source": [
        "# 2. Extração de ngramas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEk6F4P0uv4d"
      },
      "source": [
        "# Definição de função que retorna os ngramas de um texto\n",
        "def n_gramas(sentenca, n):\n",
        "  ngramas = []\n",
        "  tokens = re.sub(r'([^\\s\\w]|_)+', ' ', sentenca).split()\n",
        "  for i in range(len(tokens)-n+1):\n",
        "    ngramas.append(tokens[i:i+n])\n",
        "  return ngramas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wktO45L3yOdW",
        "outputId": "ece58823-6823-41ea-e355-03e60fa4c4c0"
      },
      "source": [
        "# Testando a nossa função\n",
        "print(n_gramas(\"\"\"São Paulo FC was founded on 25 January 1930 by 60 former officials, \n",
        "players, members, and friends of the football clubs Club Athletico Paulistano and \n",
        "Associação Atlética das Palmeiras of São Paulo.\"\"\", 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['São', 'Paulo'], ['Paulo', 'FC'], ['FC', 'was'], ['was', 'founded'], ['founded', 'on'], ['on', '25'], ['25', 'January'], ['January', '1930'], ['1930', 'by'], ['by', '60'], ['60', 'former'], ['former', 'officials'], ['officials', 'players'], ['players', 'members'], ['members', 'and'], ['and', 'friends'], ['friends', 'of'], ['of', 'the'], ['the', 'football'], ['football', 'clubs'], ['clubs', 'Club'], ['Club', 'Athletico'], ['Athletico', 'Paulistano'], ['Paulistano', 'and'], ['and', 'Associação'], ['Associação', 'Atlética'], ['Atlética', 'das'], ['das', 'Palmeiras'], ['Palmeiras', 'of'], ['of', 'São'], ['São', 'Paulo']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMS8TWJbzXG7",
        "outputId": "98b724d4-6910-42d8-acf3-391186d76c21"
      },
      "source": [
        "# Usando um função do pacote nltk para encontrar os ngramas\n",
        "from nltk import ngrams\n",
        "list(ngrams(\"\"\"São Paulo FC was founded on 25 January 1930 by 60 former officials, \n",
        "players, members, and friends of the football clubs Club Athletico Paulistano and \n",
        "Associação Atlética das Palmeiras of São Paulo.\"\"\".split(), 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('São', 'Paulo'),\n",
              " ('Paulo', 'FC'),\n",
              " ('FC', 'was'),\n",
              " ('was', 'founded'),\n",
              " ('founded', 'on'),\n",
              " ('on', '25'),\n",
              " ('25', 'January'),\n",
              " ('January', '1930'),\n",
              " ('1930', 'by'),\n",
              " ('by', '60'),\n",
              " ('60', 'former'),\n",
              " ('former', 'officials,'),\n",
              " ('officials,', 'players,'),\n",
              " ('players,', 'members,'),\n",
              " ('members,', 'and'),\n",
              " ('and', 'friends'),\n",
              " ('friends', 'of'),\n",
              " ('of', 'the'),\n",
              " ('the', 'football'),\n",
              " ('football', 'clubs'),\n",
              " ('clubs', 'Club'),\n",
              " ('Club', 'Athletico'),\n",
              " ('Athletico', 'Paulistano'),\n",
              " ('Paulistano', 'and'),\n",
              " ('and', 'Associação'),\n",
              " ('Associação', 'Atlética'),\n",
              " ('Atlética', 'das'),\n",
              " ('das', 'Palmeiras'),\n",
              " ('Palmeiras', 'of'),\n",
              " ('of', 'São'),\n",
              " ('São', 'Paulo.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrrUG6FP0LTR",
        "outputId": "61ab01d0-462b-4b80-e5d3-f759c1757bff"
      },
      "source": [
        "# Usando uma função do pacote textblob para encontrar os ngramas\n",
        "!pip install -U textblob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOYhZnZB2bAZ",
        "outputId": "7bb20d21-4225-4a79-b785-a0b4f27d8fad"
      },
      "source": [
        "# Testando o pacote blob\n",
        "blob = TextBlob(\"\"\"São Paulo FC was founded on 25 January 1930 by 60 former officials, \n",
        "players, members, and friends of the football clubs Club Athletico Paulistano and \n",
        "Associação Atlética das Palmeiras of São Paulo.\"\"\")\n",
        "blob.ngrams(n=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['São', 'Paulo', 'FC']),\n",
              " WordList(['Paulo', 'FC', 'was']),\n",
              " WordList(['FC', 'was', 'founded']),\n",
              " WordList(['was', 'founded', 'on']),\n",
              " WordList(['founded', 'on', '25']),\n",
              " WordList(['on', '25', 'January']),\n",
              " WordList(['25', 'January', '1930']),\n",
              " WordList(['January', '1930', 'by']),\n",
              " WordList(['1930', 'by', '60']),\n",
              " WordList(['by', '60', 'former']),\n",
              " WordList(['60', 'former', 'officials']),\n",
              " WordList(['former', 'officials', 'players']),\n",
              " WordList(['officials', 'players', 'members']),\n",
              " WordList(['players', 'members', 'and']),\n",
              " WordList(['members', 'and', 'friends']),\n",
              " WordList(['and', 'friends', 'of']),\n",
              " WordList(['friends', 'of', 'the']),\n",
              " WordList(['of', 'the', 'football']),\n",
              " WordList(['the', 'football', 'clubs']),\n",
              " WordList(['football', 'clubs', 'Club']),\n",
              " WordList(['clubs', 'Club', 'Athletico']),\n",
              " WordList(['Club', 'Athletico', 'Paulistano']),\n",
              " WordList(['Athletico', 'Paulistano', 'and']),\n",
              " WordList(['Paulistano', 'and', 'Associação']),\n",
              " WordList(['and', 'Associação', 'Atlética']),\n",
              " WordList(['Associação', 'Atlética', 'das']),\n",
              " WordList(['Atlética', 'das', 'Palmeiras']),\n",
              " WordList(['das', 'Palmeiras', 'of']),\n",
              " WordList(['Palmeiras', 'of', 'São']),\n",
              " WordList(['of', 'São', 'Paulo'])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLuW2Uo92_c4"
      },
      "source": [
        "# 3. Tokenização usando keras e bloob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "untZ170U3Rp4"
      },
      "source": [
        "# Importando keras e textblob\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "929Q4guL5ZE7"
      },
      "source": [
        "# Senteça que usaremos\n",
        "sentenca = \"\"\"São Paulo is the third best-supported club in Brazil, with over 16 million supporters.[6] \n",
        "The team's traditional home kit is a white shirt with two horizontal stripes (one red and one black), \n",
        "white shorts, and white socks.[7] Its home ground is the 72,039-seater[1] Morumbi football stadium in São Paulo,\n",
        "[8] where it has played since 1960.[9] The stadium was the venue for the Copa Libertadores finals \n",
        "of 1992, 1993, 1994, 2000, 2003, 2005 and 2006. São Paulo is the second richest Brazilian \n",
        "football club in terms of revenue, with an annual revenue of $111.9m (€78.2m), and the \n",
        "nation's second most valuable club, worth over $353.4m (€246.9m) in 2011.[10]\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xruPhisn6MZo"
      },
      "source": [
        "# Definindo função que tokeniza usando keras\n",
        "def tokens_keras(texto):\n",
        "  return text_to_word_sequence(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpTMsfUW6ZsF",
        "outputId": "9339ce48-7b06-4804-fab9-3317a8e1b110"
      },
      "source": [
        "# Testando a função\n",
        "tokens_keras(sentenca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['são',\n",
              " 'paulo',\n",
              " 'is',\n",
              " 'the',\n",
              " 'third',\n",
              " 'best',\n",
              " 'supported',\n",
              " 'club',\n",
              " 'in',\n",
              " 'brazil',\n",
              " 'with',\n",
              " 'over',\n",
              " '16',\n",
              " 'million',\n",
              " 'supporters',\n",
              " '6',\n",
              " 'the',\n",
              " \"team's\",\n",
              " 'traditional',\n",
              " 'home',\n",
              " 'kit',\n",
              " 'is',\n",
              " 'a',\n",
              " 'white',\n",
              " 'shirt',\n",
              " 'with',\n",
              " 'two',\n",
              " 'horizontal',\n",
              " 'stripes',\n",
              " 'one',\n",
              " 'red',\n",
              " 'and',\n",
              " 'one',\n",
              " 'black',\n",
              " 'white',\n",
              " 'shorts',\n",
              " 'and',\n",
              " 'white',\n",
              " 'socks',\n",
              " '7',\n",
              " 'its',\n",
              " 'home',\n",
              " 'ground',\n",
              " 'is',\n",
              " 'the',\n",
              " '72',\n",
              " '039',\n",
              " 'seater',\n",
              " '1',\n",
              " 'morumbi',\n",
              " 'football',\n",
              " 'stadium',\n",
              " 'in',\n",
              " 'são',\n",
              " 'paulo',\n",
              " '8',\n",
              " 'where',\n",
              " 'it',\n",
              " 'has',\n",
              " 'played',\n",
              " 'since',\n",
              " '1960',\n",
              " '9',\n",
              " 'the',\n",
              " 'stadium',\n",
              " 'was',\n",
              " 'the',\n",
              " 'venue',\n",
              " 'for',\n",
              " 'the',\n",
              " 'copa',\n",
              " 'libertadores',\n",
              " 'finals',\n",
              " 'of',\n",
              " '1992',\n",
              " '1993',\n",
              " '1994',\n",
              " '2000',\n",
              " '2003',\n",
              " '2005',\n",
              " 'and',\n",
              " '2006',\n",
              " 'são',\n",
              " 'paulo',\n",
              " 'is',\n",
              " 'the',\n",
              " 'second',\n",
              " 'richest',\n",
              " 'brazilian',\n",
              " 'football',\n",
              " 'club',\n",
              " 'in',\n",
              " 'terms',\n",
              " 'of',\n",
              " 'revenue',\n",
              " 'with',\n",
              " 'an',\n",
              " 'annual',\n",
              " 'revenue',\n",
              " 'of',\n",
              " '111',\n",
              " '9m',\n",
              " '€78',\n",
              " '2m',\n",
              " 'and',\n",
              " 'the',\n",
              " \"nation's\",\n",
              " 'second',\n",
              " 'most',\n",
              " 'valuable',\n",
              " 'club',\n",
              " 'worth',\n",
              " 'over',\n",
              " '353',\n",
              " '4m',\n",
              " '€246',\n",
              " '9m',\n",
              " 'in',\n",
              " '2011',\n",
              " '10']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrp6DJzd6pH_"
      },
      "source": [
        "# Definindo função para obter tokens usando textblob\n",
        "def tokens_textblob(text):\n",
        "  blob = TextBlob(text)\n",
        "  return blob.words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HofyUqY964Yy",
        "outputId": "b089c48a-878c-45fd-b510-5394af771bbc"
      },
      "source": [
        "# Testando a função\n",
        "tokens_textblob(sentenca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['São', 'Paulo', 'is', 'the', 'third', 'best-supported', 'club', 'in', 'Brazil', 'with', 'over', '16', 'million', 'supporters', '6', 'The', 'team', \"'s\", 'traditional', 'home', 'kit', 'is', 'a', 'white', 'shirt', 'with', 'two', 'horizontal', 'stripes', 'one', 'red', 'and', 'one', 'black', 'white', 'shorts', 'and', 'white', 'socks', '7', 'Its', 'home', 'ground', 'is', 'the', '72,039-seater', '1', 'Morumbi', 'football', 'stadium', 'in', 'São', 'Paulo', '8', 'where', 'it', 'has', 'played', 'since', '1960', '9', 'The', 'stadium', 'was', 'the', 'venue', 'for', 'the', 'Copa', 'Libertadores', 'finals', 'of', '1992', '1993', '1994', '2000', '2003', '2005', 'and', '2006', 'São', 'Paulo', 'is', 'the', 'second', 'richest', 'Brazilian', 'football', 'club', 'in', 'terms', 'of', 'revenue', 'with', 'an', 'annual', 'revenue', 'of', '111.9m', '€78.2m', 'and', 'the', 'nation', \"'s\", 'second', 'most', 'valuable', 'club', 'worth', 'over', '353.4m', '€246.9m', 'in', '2011', '10'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCA4v69E6_9_"
      },
      "source": [
        "# 4. Usando diferentes tokenizadores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3EbED0n7Fzt"
      },
      "source": [
        "Alguns diferentes tokenizadores:\n",
        "\n",
        "* **Whitespace tokenizer:** este é o tipo mais simples de tokenizador. Ele divide uma string sempre que um caractere de espaço, tabulação ou nova linha estiver presente.\n",
        "\n",
        "* **Tweet tokenizer:** projetado especificamente para tokenizar tweets. Ele cuida de todos os caracteres especiais e emojis usados em tweets e retorna tokens limpos.\n",
        "\n",
        "* **MWE tokenizer:** MWE significa Multi-Word Expression. Aqui, certos grupos de palavras são tratados como uma entidade durante a tokenização, como \"United States of America\", \"People's Republic of China\", \"not only\" e \"but also\". Esses grupos predefinidos são adicionados no início com métodos mwe().\n",
        "\n",
        "* **Regular expression tokenizer:** esses tokenizadores são desenvolvidos usando expressões regulares. As frases são divididas com base na ocorrência de um padrão específico (uma expressão regular).\n",
        "\n",
        "* **WordPunctTokenizer:** divide um trecho de texto em uma lista de caracteres alfabéticos e não alfabéticos. Ou seja, faz uma tokenizaão também considerando pontos e outros caracteres especiais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzlDWjoI8Tmk"
      },
      "source": [
        "# Importando os diferentes tokenizers\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujdBkIe6BVXR"
      },
      "source": [
        "# Sentença que usaremos\n",
        "sentenca = 'Sunil tweeted, \"Witnessing 70th Republic Day of India from Rajpath, \\\n",
        "New Delhi. Mesmerizing performance by Indian Army! Awesome airshow! @india_official \\\n",
        "@indian_army #India #70thRepublic_Day. For more photos ping me sunil@photoking.com :)\"'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UVFUJxABwl6"
      },
      "source": [
        "# Tokenizer para tweets\n",
        "def tweet_tokens(texto):\n",
        "  tokenizer = TweetTokenizer()\n",
        "  return tokenizer.tokenize(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz5iDKM4CQi0"
      },
      "source": [
        "# Tokenizer para multi-word expressions\n",
        "def mwe_tokenizer(texto):\n",
        "  tokenizer = MWETokenizer()\n",
        "  tokenizer.add_mwe(('New', 'Delhi.'))\n",
        "  return tokenizer.tokenize(texto.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k26ASPsCw2R"
      },
      "source": [
        "# Tokenizer com regex\n",
        "def regex_tokenizer(texto):\n",
        "  tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
        "  return tokenizer.tokenize(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekdaXZhWFNTj"
      },
      "source": [
        "# Tokenizer baseado em espaços em branco\n",
        "def ws_tokenizer(texto):\n",
        "  tokenizer = WhitespaceTokenizer()\n",
        "  return tokenizer.tokenize(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnwjkj6oFbkI"
      },
      "source": [
        "# Tokenizer WordPunct\n",
        "def wordpunct_tokenizer(texto):\n",
        "  tokenizer = WordPunctTokenizer()\n",
        "  return tokenizer.tokenize(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjDIuq0uGZw-",
        "outputId": "e95e0d53-110f-49da-bfee-58c9640baa46"
      },
      "source": [
        "print(tweet_tokens(sentenca))\n",
        "print(\"##############\")\n",
        "print(mwe_tokenizer(sentenca))\n",
        "print(\"##############\")\n",
        "print(regex_tokenizer(sentenca))\n",
        "print(\"##############\")\n",
        "print(ws_tokenizer(sentenca))\n",
        "print(\"##############\")\n",
        "print(wordpunct_tokenizer(sentenca))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sunil', 'tweeted', ',', '\"', 'Witnessing', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath', ',', 'New', 'Delhi', '.', 'Mesmerizing', 'performance', 'by', 'Indian', 'Army', '!', 'Awesome', 'airshow', '!', '@india_official', '@indian_army', '#India', '#70thRepublic_Day', '.', 'For', 'more', 'photos', 'ping', 'me', 'sunil@photoking.com', ':)', '\"']\n",
            "##############\n",
            "['Sunil', 'tweeted,', '\"Witnessing', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath,', 'New_Delhi.', 'Mesmerizing', 'performance', 'by', 'Indian', 'Army!', 'Awesome', 'airshow!', '@india_official', '@indian_army', '#India', '#70thRepublic_Day.', 'For', 'more', 'photos', 'ping', 'me', 'sunil@photoking.com', ':)\"']\n",
            "##############\n",
            "['Sunil', 'tweeted', ',', '\"Witnessing', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath', ',', 'New', 'Delhi', '.', 'Mesmerizing', 'performance', 'by', 'Indian', 'Army', '!', 'Awesome', 'airshow', '!', '@india_official', '@indian_army', '#India', '#70thRepublic_Day.', 'For', 'more', 'photos', 'ping', 'me', 'sunil', '@photoking.com', ':)\"']\n",
            "##############\n",
            "['Sunil', 'tweeted,', '\"Witnessing', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath,', 'New', 'Delhi.', 'Mesmerizing', 'performance', 'by', 'Indian', 'Army!', 'Awesome', 'airshow!', '@india_official', '@indian_army', '#India', '#70thRepublic_Day.', 'For', 'more', 'photos', 'ping', 'me', 'sunil@photoking.com', ':)\"']\n",
            "##############\n",
            "['Sunil', 'tweeted', ',', '\"', 'Witnessing', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath', ',', 'New', 'Delhi', '.', 'Mesmerizing', 'performance', 'by', 'Indian', 'Army', '!', 'Awesome', 'airshow', '!', '@', 'india_official', '@', 'indian_army', '#', 'India', '#', '70thRepublic_Day', '.', 'For', 'more', 'photos', 'ping', 'me', 'sunil', '@', 'photoking', '.', 'com', ':)\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xO8bxu4IItd"
      },
      "source": [
        "# 5. Convertendo palavras com Stemmers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ph1shiGIPzl"
      },
      "source": [
        "# Importando RegexStemmer para converter palavras em sua forma básica\n",
        "from nltk.stem import RegexpStemmer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYwX6udaIwPQ"
      },
      "source": [
        "# Definindo a função para pegar os stems\n",
        "def get_stems_regex(texto):\n",
        "  # Criando objeto RegexStemmer que remove -ing do final de palavras com mais de quatro letras\n",
        "  stemmer = RegexpStemmer('ing$', min=4)\n",
        "  return \" \".join([stemmer.stem(palavra) for palavra in texto.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O69ZyuHRJPf7"
      },
      "source": [
        "# Importando o Porter Stemmer\n",
        "from nltk.stem.porter import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhKmxFHPK65i"
      },
      "source": [
        "# Definindo função para usar o Stemmer de Porter\n",
        "def get_stems_porter(texto):\n",
        "  stemmer = PorterStemmer()\n",
        "  return \" \".join([stemmer.stem(palavra) for palavra in texto.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFjX--StLUmb",
        "outputId": "90663a9a-4e04-45d5-b5d5-071b6e9275cd"
      },
      "source": [
        "# Testando ambos os stemmers\n",
        "sentenca = \"Before eating it would be nice to sanitize your hands with a sanitizer\"\n",
        "print(get_stems_regex(sentenca))\n",
        "print(get_stems_porter(sentenca))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before eat it would be nice to sanitize your hands with a sanitizer\n",
            "befor eat it would be nice to sanit your hand with a sanit\n"
          ]
        }
      ]
    }
  ]
}